<!DOCTYPE html>
<html lang="en">

<head>
    <meta charset="UTF-8">
<meta name="viewport"
      content="width=device-width, initial-scale=1.0, maximum-scale=1.0, minimum-scale=1.0">
<meta http-equiv="X-UA-Compatible" content="ie=edge">

    <meta name="author" content="WuBoyue">





<title>CNN | Edith</title>



    <link rel="icon" href="/favicon.ico">




    <!-- stylesheets list from _config.yml -->
    
    <link rel="stylesheet" href="/css/style.css">
    



    <!-- scripts list from _config.yml -->
    
    <script src="/js/script.js"></script>
    
    <script src="/js/tocbot.min.js"></script>
    



    
    
        <!-- MathJax配置，可通过单美元符号书写行内公式等 -->
<script type="text/x-mathjax-config">
    MathJax.Hub.Config({
    "HTML-CSS": {
        preferredFont: "TeX",
        availableFonts: ["STIX","TeX"],
        linebreaks: { automatic:true },
        EqnChunk: (MathJax.Hub.Browser.isMobile ? 10 : 50)
    },
    tex2jax: {
        inlineMath: [ ["$", "$"], ["\\(","\\)"] ],
        processEscapes: true,
        ignoreClass: "tex2jax_ignore|dno",
        skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
    },
    TeX: {
        equationNumbers: { autoNumber: "AMS" },
        noUndefined: { attributes: { mathcolor: "red", mathbackground: "#FFEEEE", mathsize: "90%" } },
        Macros: { href: "{}" }
    },
    messageStyle: "none"
    });
</script>
<!-- 给MathJax元素添加has-jax class -->
<script type="text/x-mathjax-config">
    MathJax.Hub.Queue(function() {
        var all = MathJax.Hub.getAllJax(), i;
        for(i=0; i < all.length; i += 1) {
            all[i].SourceElement().parentNode.className += ' has-jax';
        }
    });
</script>
<!-- 通过连接CDN加载MathJax的js代码 -->
<script type="text/javascript" async
        src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-MML-AM_CHTML">
</script>


    


<meta name="generator" content="Hexo 7.2.0"></head>

<body>
    <script>
        // this function is used to check current theme before page loaded.
        (() => {
            const currentTheme = window.localStorage && window.localStorage.getItem('theme') || '';
            const isDark = currentTheme === 'dark';
            const pagebody = document.getElementsByTagName('body')[0]
            if (isDark) {
                pagebody.classList.add('dark-theme');
                // mobile
                document.getElementById("mobile-toggle-theme").innerText = "· Dark"
            } else {
                pagebody.classList.remove('dark-theme');
                // mobile
                document.getElementById("mobile-toggle-theme").innerText = "· Light"
            }
        })();

    </script>

    <script>// 蜘蛛网特效.
	!function () {
		    function n(n, e, t) {
		        return n.getAttribute(e) || t
		    }
		 
		    function e(n) {
		        return document.getElementsByTagName(n)
		    }
		 
		    function t() {
		        var t = e("script"), o = t.length, i = t[o - 1];
		        return {l: o, z: n(i, "zIndex", -1), o: n(i, "opacity", .5), c: n(i, "color", "0,0,0"), n: n(i, "count", 99)}
		    }
		 
		    function o() {
		        a = m.width = window.innerWidth || document.documentElement.clientWidth || document.body.clientWidth, c = m.height = window.innerHeight || document.documentElement.clientHeight || document.body.clientHeight
		    }
		 
		    function i() {
		        r.clearRect(0, 0, a, c);
		        var n, e, t, o, m, l;
		        s.forEach(function (i, x) {
		            for (i.x += i.xa, i.y += i.ya, i.xa *= i.x > a || i.x < 0 ? -1 : 1, i.ya *= i.y > c || i.y < 0 ? -1 : 1, r.fillRect(i.x - .5, i.y - .5, 1, 1), e = x + 1; e < u.length; e++) n = u[e], null !== n.x && null !== n.y && (o = i.x - n.x, m = i.y - n.y, l = o * o + m * m, l < n.max && (n === y && l >= n.max / 2 && (i.x -= .03 * o, i.y -= .03 * m), t = (n.max - l) / n.max, r.beginPath(), r.lineWidth = t / 2, r.strokeStyle = "rgba(" + d.c + "," + (t + .2) + ")", r.moveTo(i.x, i.y), r.lineTo(n.x, n.y), r.stroke()))
		        }), x(i)
		    }
		 
		    var a, c, u, m = document.createElement("canvas"), d = t(), l = "c_n" + d.l, r = m.getContext("2d"),
		        x = window.requestAnimationFrame || window.webkitRequestAnimationFrame || window.mozRequestAnimationFrame || window.oRequestAnimationFrame || window.msRequestAnimationFrame || function (n) {
		            window.setTimeout(n, 1e3 / 45)
		        }, w = Math.random, y = {x: null, y: null, max: 2e4};
		    m.id = l, m.style.cssText = "position:fixed;top:0;left:0;z-index:" + d.z + ";opacity:" + d.o, e("body")[0].appendChild(m), o(), window.onresize = o, window.onmousemove = function (n) {
		        n = n || window.event, y.x = n.clientX, y.y = n.clientY
		    }, window.onmouseout = function () {
		        y.x = null, y.y = null
		    };
		    for (var s = [], f = 0; d.n > f; f++) {
		        var h = w() * a, g = w() * c, v = 2 * w() - 1, p = 2 * w() - 1;
		        s.push({x: h, y: g, xa: v, ya: p, max: 6e3})
		    }
		    u = s.concat([y]), setTimeout(function () {
		        i()
		    }, 100)
		}();
    </script>

    <script>// 鼠标点击烟花
    function clickEffect() {
      let balls = [];
      let longPressed = false;
      let longPress;
      let multiplier = 0;
      let width, height;
      let origin;
      let normal;
      let ctx;
      const colours = ["#F73859", "#14FFEC", "#00E0FF", "#FF99FE", "#FAF15D"];
      const canvas = document.createElement("canvas");
      document.body.appendChild(canvas);
      canvas.setAttribute("style", "width: 100%; height: 100%; top: 0; left: 0; z-index: 99999; position: fixed; pointer-events: none;");
      const pointer = document.createElement("span");
      pointer.classList.add("pointer");
      document.body.appendChild(pointer);
     
      if (canvas.getContext && window.addEventListener) {
        ctx = canvas.getContext("2d");
        updateSize();
        window.addEventListener('resize', updateSize, false);
        loop();
        window.addEventListener("mousedown", function(e) {
          pushBalls(randBetween(10, 20), e.clientX, e.clientY);
          document.body.classList.add("is-pressed");
          longPress = setTimeout(function(){
            document.body.classList.add("is-longpress");
            longPressed = true;
          }, 500);
        }, false);
        window.addEventListener("mouseup", function(e) {
          clearInterval(longPress);
          if (longPressed == true) {
            document.body.classList.remove("is-longpress");
            pushBalls(randBetween(50 + Math.ceil(multiplier), 100 + Math.ceil(multiplier)), e.clientX, e.clientY);
            longPressed = false;
          }
          document.body.classList.remove("is-pressed");
        }, false);
        window.addEventListener("mousemove", function(e) {
          let x = e.clientX;
          let y = e.clientY;
          pointer.style.top = y + "px";
          pointer.style.left = x + "px";
        }, false);
      } else {
        console.log("canvas or addEventListener is unsupported!");
      }
     
     
      function updateSize() {
        canvas.width = window.innerWidth * 2;
        canvas.height = window.innerHeight * 2;
        canvas.style.width = window.innerWidth + 'px';
        canvas.style.height = window.innerHeight + 'px';
        ctx.scale(2, 2);
        width = (canvas.width = window.innerWidth);
        height = (canvas.height = window.innerHeight);
        origin = {
          x: width / 2,
          y: height / 2
        };
        normal = {
          x: width / 2,
          y: height / 2
        };
      }
      class Ball {
        constructor(x = origin.x, y = origin.y) {
          this.x = x;
          this.y = y;
          this.angle = Math.PI * 2 * Math.random();
          if (longPressed == true) {
            this.multiplier = randBetween(14 + multiplier, 15 + multiplier);
          } else {
            this.multiplier = randBetween(6, 12);
          }
          this.vx = (this.multiplier + Math.random() * 0.5) * Math.cos(this.angle);
          this.vy = (this.multiplier + Math.random() * 0.5) * Math.sin(this.angle);
          this.r = randBetween(8, 12) + 3 * Math.random();
          this.color = colours[Math.floor(Math.random() * colours.length)];
        }
        update() {
          this.x += this.vx - normal.x;
          this.y += this.vy - normal.y;
          normal.x = -2 / window.innerWidth * Math.sin(this.angle);
          normal.y = -2 / window.innerHeight * Math.cos(this.angle);
          this.r -= 0.3;
          this.vx *= 0.9;
          this.vy *= 0.9;
        }
      }
     
      function pushBalls(count = 1, x = origin.x, y = origin.y) {
        for (let i = 0; i < count; i++) {
          balls.push(new Ball(x, y));
        }
      }
     
      function randBetween(min, max) {
        return Math.floor(Math.random() * max) + min;
      }
     
      function loop() {
        ctx.fillStyle = "rgba(255, 255, 255, 0)";
        ctx.clearRect(0, 0, canvas.width, canvas.height);
        for (let i = 0; i < balls.length; i++) {
          let b = balls[i];
          if (b.r < 0) continue;
          ctx.fillStyle = b.color;
          ctx.beginPath();
          ctx.arc(b.x, b.y, b.r, 0, Math.PI * 2, false);
          ctx.fill();
          b.update();
        }
        if (longPressed == true) {
          multiplier += 0.2;
        } else if (!longPressed && multiplier >= 0) {
          multiplier -= 0.4;
        }
        removeBall();
        requestAnimationFrame(loop);
      }
     
      function removeBall() {
        for (let i = 0; i < balls.length; i++) {
          let b = balls[i];
          if (b.x + b.r < 0 || b.x - b.r > width || b.y + b.r < 0 || b.y - b.r > height || b.r < 0) {
            balls.splice(i, 1);
          }
        }
      }
    }
    clickEffect();//调用特效函数
    </script>

    <!-- <script>
    //宇宙特效
    "use strict";
    var canvas = document.getElementById('canvas'),
      ctx = canvas.getContext('2d'),
      w = canvas.width = window.innerWidth,
      h = canvas.height = window.innerHeight,
     
      hue = 217,
      stars = [],
      count = 0,
      maxStars = 2500;//星星数量
     
    var canvas2 = document.createElement('canvas'),
      ctx2 = canvas2.getContext('2d');
    canvas2.width = 100;
    canvas2.height = 100;
    var half = canvas2.width / 2,
      gradient2 = ctx2.createRadialGradient(half, half, 0, half, half, half);
    gradient2.addColorStop(0.025, '#CCC');
    gradient2.addColorStop(0.1, 'hsl(' + hue + ', 61%, 33%)');
    gradient2.addColorStop(0.25, 'hsl(' + hue + ', 64%, 6%)');
    gradient2.addColorStop(1, 'transparent');
     
    ctx2.fillStyle = gradient2;
    ctx2.beginPath();
    ctx2.arc(half, half, half, 0, Math.PI * 2);
    ctx2.fill();
     
    // End cache
     
    function random(min, max) {
      if (arguments.length < 2) {
        max = min;
        min = 0;
      }
     
      if (min > max) {
        var hold = max;
        max = min;
        min = hold;
      }
     
      return Math.floor(Math.random() * (max - min + 1)) + min;
    }
     
    function maxOrbit(x, y) {
      var max = Math.max(x, y),
        diameter = Math.round(Math.sqrt(max * max + max * max));
      return diameter / 2;
      //星星移动范围，值越大范围越小，
    }
     
    var Star = function() {
     
      this.orbitRadius = random(maxOrbit(w, h));
      this.radius = random(60, this.orbitRadius) / 18; 
      //星星大小
      this.orbitX = w / 2;
      this.orbitY = h / 2;
      this.timePassed = random(0, maxStars);
      this.speed = random(this.orbitRadius) / 500000; 
      //星星移动速度
      this.alpha = random(2, 10) / 10;
     
      count++;
      stars[count] = this;
    }
     
    Star.prototype.draw = function() {
      var x = Math.sin(this.timePassed) * this.orbitRadius + this.orbitX,
        y = Math.cos(this.timePassed) * this.orbitRadius + this.orbitY,
        twinkle = random(10);
     
      if (twinkle === 1 && this.alpha > 0) {
        this.alpha -= 0.05;
      } else if (twinkle === 2 && this.alpha < 1) {
        this.alpha += 0.05;
      }
     
      ctx.globalAlpha = this.alpha;
      ctx.drawImage(canvas2, x - this.radius / 2, y - this.radius / 2, this.radius, this.radius);
      this.timePassed += this.speed;
    }
     
    for (var i = 0; i < maxStars; i++) {
      new Star();
    }
     
    function animation() {
      ctx.globalCompositeOperation = 'source-over';
      ctx.globalAlpha = 0.5; //尾巴
      ctx.fillStyle = 'hsla(' + hue + ', 64%, 6%, 2)';
      ctx.fillRect(0, 0, w, h)
     
      ctx.globalCompositeOperation = 'lighter';
      for (var i = 1, l = stars.length; i < l; i++) {
        stars[i].draw();
      };
      window.requestAnimationFrame(animation);
    }
     
    animation();
    </script> -->

<script>//鼠标星星
    function fairyDustCursor() {

        var possibleColors = ["#D61C59", "#E7D84B", "#1B8798"]
        var width = window.innerWidth;
        var height = window.innerHeight;
        var cursor = { x: width / 2, y: width / 2 };
        var particles = [];

        function init() {
            bindEvents();
            loop();
        }

        // Bind events that are needed
        function bindEvents() {
            document.addEventListener('mousemove', onMouseMove);
            window.addEventListener('resize', onWindowResize);
        }

        function onWindowResize(e) {
            width = window.innerWidth;
            height = window.innerHeight;
        }

        function onMouseMove(e) {
            cursor.x = e.clientX;
            cursor.y = e.clientY;

            addParticle(cursor.x, cursor.y, possibleColors[Math.floor(Math.random() * possibleColors.length)]);
        }

        function addParticle(x, y, color) {
            var particle = new Particle();
            particle.init(x, y, color);
            particles.push(particle);
        }

        function updateParticles() {

            // Updated
            for (var i = 0; i < particles.length; i++) {
                particles[i].update();
            }

            // Remove dead particles
            for (var i = particles.length - 1; i >= 0; i--) {
                if (particles[i].lifeSpan < 0) {
                    particles[i].die();
                    particles.splice(i, 1);
                }
            }

        }

        function loop() {
            requestAnimationFrame(loop);
            updateParticles();
        }

        /**
         * Particles
         */

        function Particle() {

            this.character = "*";
            this.lifeSpan = 120; //ms
            this.initialStyles = {
                "position": "fixed",
                "display": "inline-block",
                "top": "0px",
                "left": "0px",
                "pointerEvents": "none",
                "touch-action": "none",
                "z-index": "10000000",
                "fontSize": "25px",
                "will-change": "transform"
            };

            // Init, and set properties
            this.init = function (x, y, color) {

                this.velocity = {
                    x: (Math.random() < 0.5 ? -1 : 1) * (Math.random() / 2),
                    y: 1
                };

                this.position = { x: x + 10, y: y + 10 };
                this.initialStyles.color = color;

                this.element = document.createElement('span');
                this.element.innerHTML = this.character;
                applyProperties(this.element, this.initialStyles);
                this.update();

                document.querySelector('.js-cursor-container').appendChild(this.element);
            };

            this.update = function () {
                this.position.x += this.velocity.x;
                this.position.y += this.velocity.y;
                this.lifeSpan--;

                this.element.style.transform = "translate3d(" + this.position.x + "px," + this.position.y + "px, 0) scale(" + (this.lifeSpan / 120) + ")";
            }

            this.die = function () {
                this.element.parentNode.removeChild(this.element);
            }

        }

        /**
         * Utils
         */

        // Applies css `properties` to an element.
        function applyProperties(target, properties) {
            for (var key in properties) {
                target.style[key] = properties[key];
            }
        }

        if (!('ontouchstart' in window || navigator.msMaxTouchPoints)) init();
    } 
    fairyDustCursor();   
</script>

    <div class="wrapper">
        <header>
    <nav class="navbar">
        <div class="container">
            <div class="navbar-header header-logo"><a href="/">Home</a></div>
            <div class="menu navbar-right">
                
                    <a class="menu-item" href="/archives">Posts</a>
                
                    <a class="menu-item" href="/category">Categories</a>
                
                    <a class="menu-item" href="/tag">Tags</a>
                
                    <a class="menu-item" href="/about">About</a>
                
                <input id="switch_default" type="checkbox" class="switch_default">
                <label for="switch_default" class="toggleBtn"></label>
            </div>
        </div>
    </nav>

    
    <nav class="navbar-mobile" id="nav-mobile">
        <div class="container">
            <div class="navbar-header">
                <div>
                    <a href="/">Home</a><a id="mobile-toggle-theme">·&nbsp;Light</a>
                </div>
                <div class="menu-toggle" onclick="mobileBtn()">&#9776; Menu</div>
            </div>
            <div class="menu" id="mobile-menu">
                
                    <a class="menu-item" href="/archives">Posts</a>
                
                    <a class="menu-item" href="/category">Categories</a>
                
                    <a class="menu-item" href="/tag">Tags</a>
                
                    <a class="menu-item" href="/about">About</a>
                
            </div>
        </div>
    </nav>

</header>
<script>
    var mobileBtn = function f() {
        var toggleMenu = document.getElementsByClassName("menu-toggle")[0];
        var mobileMenu = document.getElementById("mobile-menu");
        if(toggleMenu.classList.contains("active")){
           toggleMenu.classList.remove("active")
            mobileMenu.classList.remove("active")
        }else{
            toggleMenu.classList.add("active")
            mobileMenu.classList.add("active")
        }
    }
</script>
            <div class="main">
                <div class="container">
    
    
        <div class="post-toc">
    <div class="tocbot-list">
    </div>
    <div class="tocbot-list-menu">
        <a class="tocbot-toc-expand" onclick="expand_toc()">Expand all</a>
        <a onclick="go_top()">Back to top</a>
        <a onclick="go_bottom()">Go to bottom</a>
    </div>
</div>

<script>
    var tocbot_timer;
    var DEPTH_MAX = 6; // 为 6 时展开所有
    var tocbot_default_config = {
        tocSelector: '.tocbot-list',
        contentSelector: '.post-content',
        headingSelector: 'h1, h2, h3, h4, h5',
        orderedList: false,
        scrollSmooth: true,
        onClick: extend_click,
    };

    function extend_click() {
        clearTimeout(tocbot_timer);
        tocbot_timer = setTimeout(function() {
            tocbot.refresh(obj_merge(tocbot_default_config, {
                hasInnerContainers: true
            }));
        }, 420); // 这个值是由 tocbot 源码里定义的 scrollSmoothDuration 得来的
    }

    document.ready(function() {
        tocbot.init(obj_merge(tocbot_default_config, {
            collapseDepth: 1
        }));
    });

    function expand_toc() {
        var b = document.querySelector('.tocbot-toc-expand');
        var expanded = b.getAttribute('data-expanded');
        expanded ? b.removeAttribute('data-expanded') : b.setAttribute('data-expanded', true);
        tocbot.refresh(obj_merge(tocbot_default_config, {
            collapseDepth: expanded ? 1 : DEPTH_MAX
        }));
        b.innerText = expanded ? 'Expand all' : 'Collapse all';
    }

    function go_top() {
        window.scrollTo(0, 0);
    }

    function go_bottom() {
        window.scrollTo(0, document.body.scrollHeight);
    }

    function obj_merge(target, source) {
        for (var item in source) {
            if (source.hasOwnProperty(item)) {
                target[item] = source[item];
            }
        }
        return target;
    }
</script>
    

    
    <article class="post-wrap">
        <header class="post-header">
            <h1 class="post-title">CNN</h1>
            
                <div class="post-meta">
                    
                        Author: <a itemprop="author" rel="author" href="/">WuBoyue</a>
                    

                    
                        <span class="post-time">
                        Date: <a href="#">May 13, 2024&nbsp;&nbsp;14:09:35</a>
                        </span>
                    
                    
                </div>
            
        </header>

        <div class="post-content">
            <p>第一课：水论文的艺术</p>
<h1 id="1-CNN经典模型发展历史"><a href="#1-CNN经典模型发展历史" class="headerlink" title="1.CNN经典模型发展历史"></a>1.CNN经典模型发展历史</h1><img src="115aea6d88be40deafbfe1820e7fdf7a.jpeg" alt="115aea6d88be40deafbfe1820e7fdf7a" />





<blockquote>
<p> 参考文献:<br> [1].<a target="_blank" rel="noopener" href="https://blog.csdn.net/qq_44710986/article/details/125810589?ops_request_misc=%257B%2522request%255Fid%2522%253A%2522171558043416800222812726%2522%252C%2522scm%2522%253A%252220140713.130102334.pc%255Fall.%2522%257D&request_id=171558043416800222812726&biz_id=0&utm_medium=distribute.pc_search_result.none-task-blog-2~all~first_rank_ecpm_v1~rank_v31_ecpm-2-125810589-null-null.142%5Ev100%5Epc_search_result_base1&utm_term=cnn%E6%A8%A1%E5%9E%8B%E7%9A%84%E4%B8%80%E4%BA%9B%E6%94%B9%E8%BF%9B%E6%96%B9%E6%A1%88&spm=1018.2226.3001.4187">CNN经典模型发展进程</a>.</p>
</blockquote>
<h1 id="学习率"><a href="#学习率" class="headerlink" title="学习率"></a>学习率</h1><p>神经网络的训练参数设置主要包括学习率的设置和批数量的设置，其中学习率是梯度下降算法进行权重更新的步长，较大的学习速率允许模型更快地学习，但最终只能学习到次优的权重集，较小的学习速率可以允许模型学习到更优化或者是甚至全局最佳的权重集，但是可能花费更长的时间来训练，因此学习率的设定非常重要；而批数量指的是一次输入到网络的图像的训练样本数量，批数量过大会导致处理器负荷过重计算速度减慢，批数量过小会使得训练过程中<br>产生震荡，收敛效果不佳。</p>
<h1 id="评价指标"><a href="#评价指标" class="headerlink" title="评价指标"></a>评价指标</h1><h2 id="mAP"><a href="#mAP" class="headerlink" title="mAP"></a>mAP</h2><p><a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/504735862">一文搞懂 IOU、GIOU、DIOU、CIOU 损失函数的区别</a></p>
<p><a target="_blank" rel="noopener" href="https://blog.csdn.net/weixin_47651868/article/details/134135320">目标检测中常见参数</a></p>
<p><strong><a target="_blank" rel="noopener" href="https://github.com/rafaelpadilla/Object-Detection-Metrics">Object-Detection-Metrics</a></strong></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">evaluation</span>(<span class="params">val_dataloader, cfg, model, device, conf_thres = <span class="number">0.01</span>, nms_thresh = <span class="number">0.4</span>, iou_thres = <span class="number">0.5</span></span>):</span><br><span class="line"></span><br><span class="line">    labels = []</span><br><span class="line">    sample_metrics = []  <span class="comment"># List of tuples (TP, confs, pred)</span></span><br><span class="line">    pbar = tqdm(val_dataloader)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> imgs, targets <span class="keyword">in</span> pbar:</span><br><span class="line">        imgs = imgs.to(device).<span class="built_in">float</span>() / <span class="number">255.0</span></span><br><span class="line">        targets = targets.to(device)       </span><br><span class="line"></span><br><span class="line">        <span class="comment"># Extract labels</span></span><br><span class="line">        labels += targets[:, <span class="number">1</span>].tolist()</span><br><span class="line">        <span class="comment"># Rescale target</span></span><br><span class="line">        targets[:, <span class="number">2</span>:] = xywh2xyxy(targets[:, <span class="number">2</span>:])</span><br><span class="line">        targets[:, <span class="number">2</span>:] *= torch.tensor([cfg[<span class="string">&quot;width&quot;</span>], cfg[<span class="string">&quot;height&quot;</span>], cfg[<span class="string">&quot;width&quot;</span>], cfg[<span class="string">&quot;height&quot;</span>]]).to(device)</span><br><span class="line"></span><br><span class="line">        <span class="comment">#对预测的anchorbox进行nms处理</span></span><br><span class="line">        <span class="keyword">with</span> torch.no_grad():</span><br><span class="line">            preds = model(imgs)</span><br><span class="line"></span><br><span class="line">            <span class="comment">#特征图后处理:生成anchorbox</span></span><br><span class="line">            output = handel_preds(preds, cfg, device)</span><br><span class="line">            output_boxes = non_max_suppression(output, conf_thres = conf_thres, iou_thres = nms_thresh)</span><br><span class="line"></span><br><span class="line">        sample_metrics += get_batch_statistics(output_boxes, targets, iou_thres, device)</span><br><span class="line">        pbar.set_description(<span class="string">&quot;Evaluation model:&quot;</span>) </span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> <span class="built_in">len</span>(sample_metrics) == <span class="number">0</span>:  <span class="comment"># No detections over whole validation set.</span></span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;---- No detections over whole validation set ----&quot;</span>)</span><br><span class="line">        <span class="keyword">return</span> <span class="literal">None</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># Concatenate sample statistics</span></span><br><span class="line">    true_positives, pred_scores, pred_labels = [np.concatenate(x, <span class="number">0</span>) <span class="keyword">for</span> x <span class="keyword">in</span> <span class="built_in">list</span>(<span class="built_in">zip</span>(*sample_metrics))]</span><br><span class="line">    metrics_output = ap_per_class(true_positives, pred_scores, pred_labels, labels)</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">return</span> metrics_output     </span><br></pre></td></tr></table></figure>



<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br></pre></td><td class="code"><pre><span class="line">metrics_output = ap_per_class(true_positives, pred_scores, pred_labels, labels)</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">ap_per_class</span>(<span class="params">tp, conf, pred_cls, target_cls</span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot; Compute the average precision, given the recall and precision curves.</span></span><br><span class="line"><span class="string">    Source: https://github.com/rafaelpadilla/Object-Detection-Metrics.</span></span><br><span class="line"><span class="string">    # Arguments</span></span><br><span class="line"><span class="string">        tp:    True positives (list).</span></span><br><span class="line"><span class="string">        conf:  Objectness value from 0-1 (list).</span></span><br><span class="line"><span class="string">        pred_cls: Predicted object classes (list).</span></span><br><span class="line"><span class="string">        target_cls: True object classes (list).</span></span><br><span class="line"><span class="string">    # Returns</span></span><br><span class="line"><span class="string">        The average precision as computed in py-faster-rcnn.</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># Sort by objectness</span></span><br><span class="line">    i = np.argsort(-conf)</span><br><span class="line">    tp, conf, pred_cls = tp[i], conf[i], pred_cls[i]</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Find unique classes</span></span><br><span class="line">    unique_classes = np.unique(target_cls)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Create Precision-Recall curve and compute AP for each class</span></span><br><span class="line">    ap, p, r = [], [], []</span><br><span class="line">    <span class="keyword">for</span> c <span class="keyword">in</span> unique_classes:</span><br><span class="line">        i = pred_cls == c</span><br><span class="line">        n_gt = (target_cls == c).<span class="built_in">sum</span>()  <span class="comment"># Number of ground truth objects</span></span><br><span class="line">        n_p = i.<span class="built_in">sum</span>()  <span class="comment"># Number of predicted objects</span></span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> n_p == <span class="number">0</span> <span class="keyword">and</span> n_gt == <span class="number">0</span>:</span><br><span class="line">            <span class="keyword">continue</span></span><br><span class="line">        <span class="keyword">elif</span> n_p == <span class="number">0</span> <span class="keyword">or</span> n_gt == <span class="number">0</span>:</span><br><span class="line">            ap.append(<span class="number">0</span>)</span><br><span class="line">            r.append(<span class="number">0</span>)</span><br><span class="line">            p.append(<span class="number">0</span>)</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            <span class="comment"># Accumulate FPs and TPs</span></span><br><span class="line">            fpc = (<span class="number">1</span> - tp[i]).cumsum()</span><br><span class="line">            tpc = (tp[i]).cumsum()</span><br><span class="line"></span><br><span class="line">            <span class="comment"># Recall</span></span><br><span class="line">            recall_curve = tpc / (n_gt + <span class="number">1e-16</span>)</span><br><span class="line">            r.append(recall_curve[-<span class="number">1</span>])</span><br><span class="line"></span><br><span class="line">            <span class="comment"># Precision</span></span><br><span class="line">            precision_curve = tpc / (tpc + fpc)</span><br><span class="line">            p.append(precision_curve[-<span class="number">1</span>])</span><br><span class="line"></span><br><span class="line">            <span class="comment"># AP from recall-precision curve</span></span><br><span class="line">            ap.append(compute_ap(recall_curve, precision_curve))</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Compute F1 score (harmonic mean of precision and recall)</span></span><br><span class="line">    p, r, ap = np.array(p), np.array(r), np.array(ap)</span><br><span class="line">    f1 = <span class="number">2</span> * p * r / (p + r + <span class="number">1e-16</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> np.mean(p), np.mean(r), np.mean(ap), np.mean(f1)</span><br></pre></td></tr></table></figure>

<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">non_max_suppression</span>(<span class="params">prediction, conf_thres=<span class="number">0.3</span>, iou_thres=<span class="number">0.45</span>, classes=<span class="literal">None</span></span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;Performs Non-Maximum Suppression (NMS) on inference results</span></span><br><span class="line"><span class="string">    Returns:</span></span><br><span class="line"><span class="string">         detections with shape: nx6 (x1, y1, x2, y2, conf, cls)</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line">    nc = prediction.shape[<span class="number">2</span>] - <span class="number">5</span>  <span class="comment"># number of classes</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># Settings</span></span><br><span class="line">    <span class="comment"># (pixels) minimum and maximum box width and height</span></span><br><span class="line">    max_wh = <span class="number">4096</span></span><br><span class="line">    max_det = <span class="number">300</span>  <span class="comment"># maximum number of detections per image</span></span><br><span class="line">    max_nms = <span class="number">30000</span>  <span class="comment"># maximum number of boxes into torchvision.ops.nms()</span></span><br><span class="line">    time_limit = <span class="number">1.0</span>  <span class="comment"># seconds to quit after</span></span><br><span class="line">    multi_label = nc &gt; <span class="number">1</span>  <span class="comment"># multiple labels per box (adds 0.5ms/img)</span></span><br><span class="line"></span><br><span class="line">    t = time.time()</span><br><span class="line">    output = [torch.zeros((<span class="number">0</span>, <span class="number">6</span>), device=<span class="string">&quot;cpu&quot;</span>)] * prediction.shape[<span class="number">0</span>]</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> xi, x <span class="keyword">in</span> <span class="built_in">enumerate</span>(prediction):  <span class="comment"># image index, image inference</span></span><br><span class="line">        <span class="comment"># Apply constraints</span></span><br><span class="line">        <span class="comment"># x[((x[..., 2:4] &lt; min_wh) | (x[..., 2:4] &gt; max_wh)).any(1), 4] = 0  # width-height</span></span><br><span class="line">        x = x[x[..., <span class="number">4</span>] &gt; conf_thres]  <span class="comment"># confidence</span></span><br><span class="line"></span><br><span class="line">        <span class="comment"># If none remain process next image</span></span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">not</span> x.shape[<span class="number">0</span>]:</span><br><span class="line">            <span class="keyword">continue</span></span><br><span class="line"></span><br><span class="line">        <span class="comment"># Compute conf</span></span><br><span class="line">        x[:, <span class="number">5</span>:] *= x[:, <span class="number">4</span>:<span class="number">5</span>]  <span class="comment"># conf = obj_conf * cls_conf</span></span><br><span class="line"></span><br><span class="line">        <span class="comment"># Box (center x, center y, width, height) to (x1, y1, x2, y2)</span></span><br><span class="line">        box = xywh2xyxy(x[:, :<span class="number">4</span>])</span><br><span class="line"></span><br><span class="line">        <span class="comment"># Detections matrix nx6 (xyxy, conf, cls)</span></span><br><span class="line">        <span class="keyword">if</span> multi_label:</span><br><span class="line">            i, j = (x[:, <span class="number">5</span>:] &gt; conf_thres).nonzero(as_tuple=<span class="literal">False</span>).T</span><br><span class="line">            x = torch.cat((box[i], x[i, j + <span class="number">5</span>, <span class="literal">None</span>], j[:, <span class="literal">None</span>].<span class="built_in">float</span>()), <span class="number">1</span>)</span><br><span class="line">        <span class="keyword">else</span>:  <span class="comment"># best class only</span></span><br><span class="line">            conf, j = x[:, <span class="number">5</span>:].<span class="built_in">max</span>(<span class="number">1</span>, keepdim=<span class="literal">True</span>)</span><br><span class="line">            x = torch.cat((box, conf, j.<span class="built_in">float</span>()), <span class="number">1</span>)[conf.view(-<span class="number">1</span>) &gt; conf_thres]</span><br><span class="line"></span><br><span class="line">        <span class="comment"># Filter by class</span></span><br><span class="line">        <span class="keyword">if</span> classes <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:</span><br><span class="line">            x = x[(x[:, <span class="number">5</span>:<span class="number">6</span>] == torch.tensor(classes, device=x.device)).<span class="built_in">any</span>(<span class="number">1</span>)]</span><br><span class="line"></span><br><span class="line">        <span class="comment"># Check shape</span></span><br><span class="line">        n = x.shape[<span class="number">0</span>]  <span class="comment"># number of boxes</span></span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">not</span> n:  <span class="comment"># no boxes</span></span><br><span class="line">            <span class="keyword">continue</span></span><br><span class="line">        <span class="keyword">elif</span> n &gt; max_nms:  <span class="comment"># excess boxes</span></span><br><span class="line">            <span class="comment"># sort by confidence</span></span><br><span class="line">            x = x[x[:, <span class="number">4</span>].argsort(descending=<span class="literal">True</span>)[:max_nms]]</span><br><span class="line"></span><br><span class="line">        <span class="comment"># Batched NMS</span></span><br><span class="line">        c = x[:, <span class="number">5</span>:<span class="number">6</span>] * max_wh  <span class="comment"># classes</span></span><br><span class="line">        <span class="comment"># boxes (offset by class), scores</span></span><br><span class="line">        boxes, scores = x[:, :<span class="number">4</span>] + c, x[:, <span class="number">4</span>]</span><br><span class="line">        i = torchvision.ops.nms(boxes, scores, iou_thres)  <span class="comment"># NMS</span></span><br><span class="line">        <span class="keyword">if</span> i.shape[<span class="number">0</span>] &gt; max_det:  <span class="comment"># limit detections</span></span><br><span class="line">            i = i[:max_det]</span><br><span class="line"></span><br><span class="line">        output[xi] = x[i].detach().cpu()</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> (time.time() - t) &gt; time_limit:</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">f&#x27;WARNING: NMS time limit <span class="subst">&#123;time_limit&#125;</span>s exceeded&#x27;</span>)</span><br><span class="line">            <span class="keyword">break</span>  <span class="comment"># time limit exceeded</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> output</span><br></pre></td></tr></table></figure>







<h2 id="检测速率"><a href="#检测速率" class="headerlink" title="检测速率"></a>检测速率</h2><h1 id="深度可分离卷积"><a href="#深度可分离卷积" class="headerlink" title="深度可分离卷积"></a>深度可分离卷积</h1><h1 id="Anchor-free"><a href="#Anchor-free" class="headerlink" title="Anchor-free"></a>Anchor-free</h1><h1 id=""><a href="#" class="headerlink" title=""></a></h1><h1 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h1><p><a target="_blank" rel="noopener" href="https://www.zhihu.com/question/528661389/answer/2448182267">如何写出轻量化的目标检测算法？</a></p>
<h1 id="改进Yolo-Fast用于血细胞检测分类"><a href="#改进Yolo-Fast用于血细胞检测分类" class="headerlink" title="改进Yolo-Fast用于血细胞检测分类"></a>改进Yolo-Fast用于血细胞检测分类</h1><p><img src="/image-20240603102800279.png" alt="image-20240603102800279"></p>
<p>model，打印模型结构</p>
<p>值得注意的是用这些方法打印出来的模型结构是不会显示concat，上采样这类层的！！！</p>
<p>这是一个很好的观察！在使用<code>print(model)</code>或类似的方法查看YOLOv5模型结构时，确实不会直接显示出<code>concat</code>（拼接）和下采样这样的层。这是因为在YOLOv5的模型定义中，这些操作是在前向传播（forward pass）函数中通过PyTorch的函数调用实现的，而不是作为独立的层定义的。</p>
<p>让我们详细解释一下：</p>
<ol>
<li><p>层的定义方式：</p>
<ul>
<li>传统层：如卷积层（nn.Conv2d）、批归一化层（nn.BatchNorm2d）等，这些是通过PyTorch的<code>nn</code>模块直接定义的，会在模型打印中明确显示。</li>
<li>函数式操作：如拼接（torch.cat）、下采样（F.interpolate或nn.functional中的函数）等，这些是通过PyTorch的函数式API在代码中直接调用的，不作为模型的一部分定义。</li>
</ul>
</li>
<li><p>YOLOv5中的实现：</p>
<ul>
<li><p>拼接（Concat）：在YOLOv5中，拼接操作通常用于特征金字塔网络（FPN）或路径聚合网络（PAN）中，将不同尺度的特征图在通道维度上拼接。这是通过<code>torch.cat([x1, x2], 1)</code>这样的代码实现的，其中<code>[x1, x2]</code>是要拼接的特征图列表，<code>1</code>表示在通道维度上拼接。</p>
</li>
<li><p>下采样（Downsampling）：YOLOv5使用最大池化或步长为2的卷积来实现下采样，以减小特征图的空间尺寸。最大池化是通过<code>nn.MaxPool2d</code>定义的（会显示），而步长为2的卷积也是通过<code>nn.Conv2d</code>定义的（同样会显示）。</p>
</li>
<li><p>上采样（Upsampling）：用于FPN中，通过<code>F.interpolate</code>或<code>nn.Upsample</code>函数实现，这些是在forward函数中调用的，不会在模型结构中显示。</p>
</li>
</ul>
</li>
<li><p>示例代码：<br>以下是YOLOv5中可能的代码片段：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">YOLOLayer</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="built_in">super</span>().__init__()</span><br><span class="line">        self.conv1 = nn.Conv2d(<span class="number">64</span>, <span class="number">128</span>, <span class="number">3</span>, <span class="number">1</span>, <span class="number">1</span>)</span><br><span class="line">        self.conv2 = nn.Conv2d(<span class="number">128</span>, <span class="number">256</span>, <span class="number">3</span>, <span class="number">2</span>, <span class="number">1</span>)  <span class="comment"># 下采样</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x1, x2</span>):</span><br><span class="line">        x1 = self.conv1(x1)</span><br><span class="line">        x2 = self.conv2(x2)  <span class="comment"># 使用步长为2的卷积进行下采样</span></span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 拼接操作，不会在print(model)中显示</span></span><br><span class="line">        x = torch.cat([x1, x2], dim=<span class="number">1</span>)</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 上采样操作，同样不会显示</span></span><br><span class="line">        x = F.interpolate(x, scale_factor=<span class="number">2</span>, mode=<span class="string">&#x27;nearest&#x27;</span>)</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">return</span> x</span><br></pre></td></tr></table></figure>

<p>当您打印这个模型时，您会看到<code>conv1</code>和<code>conv2</code>层，但不会直接看到<code>torch.cat</code>和<code>F.interpolate</code>操作。</p>
</li>
<li><p>为什么这样设计：</p>
<ul>
<li>灵活性：使用函数式操作可以更灵活地控制数据流，例如动态选择要拼接的特征图。</li>
<li>简洁性：某些操作（如拼接）非常简单，不需要学习参数，将其定义为独立的层可能会使模型定义变得过于冗长。</li>
<li>计算图优化：PyTorch可以更好地优化这些功能性操作，无需将其视为单独的层。</li>
</ul>
</li>
<li><p>如何查看完整结构：</p>
<ul>
<li>查看源代码：直接阅读YOLOv5的源代码，尤其是各个模块的<code>forward</code>方法。</li>
<li>使用张量形状：在每个关键点打印张量的形状（如<code>print(x.shape)</code>），以了解数据如何流动和变形。</li>
<li>可视化工具：使用PyTorch的<code>torchviz</code>或其他工具来可视化完整的计算图。</li>
</ul>
</li>
</ol>
<p>总之，当您使用<code>print(model)</code>时看不到某些操作，这并不意味着这些操作不存在，而是因为它们是作为函数调用而不是独立的层来实现的。了解这一点可以帮助您更好地理解YOLOv5的内部工作原理。</p>
<hr>
<p>Detector(<br>  (backbone): ShuffleNetV2(<br>    (first_conv): Sequential(<br>      (0): Conv2d(3, 24, kernel_size&#x3D;(3, 3), stride&#x3D;(2, 2), padding&#x3D;(1, 1), bias&#x3D;False)<br>      (1): BatchNorm2d(24, eps&#x3D;1e-05, momentum&#x3D;0.1, affine&#x3D;True, track_running_stats&#x3D;True)<br>      (2): ReLU(inplace&#x3D;True)<br>    )<br>    (maxpool): MaxPool2d(kernel_size&#x3D;3, stride&#x3D;2, padding&#x3D;1, dilation&#x3D;1, ceil_mode&#x3D;False)</p>
<p>   (stage2): Sequential(<br>      (0): ShuffleV2Block(<br>        (branch_main): Sequential(<br>          (0): Conv2d(24, 24, kernel_size&#x3D;(1, 1), stride&#x3D;(1, 1), bias&#x3D;False)<br>          (1): BatchNorm2d(24, eps&#x3D;1e-05, momentum&#x3D;0.1, affine&#x3D;True, track_running_stats&#x3D;True)<br>          (2): ReLU(inplace&#x3D;True)<br>          (3): Conv2d(24, 24, kernel_size&#x3D;(3, 3), stride&#x3D;(2, 2), padding&#x3D;(1, 1), groups&#x3D;24, bias&#x3D;False)<br>          (4): BatchNorm2d(24, eps&#x3D;1e-05, momentum&#x3D;0.1, affine&#x3D;True, track_running_stats&#x3D;True)<br>          (5): Conv2d(24, 24, kernel_size&#x3D;(1, 1), stride&#x3D;(1, 1), bias&#x3D;False)<br>          (6): BatchNorm2d(24, eps&#x3D;1e-05, momentum&#x3D;0.1, affine&#x3D;True, track_running_stats&#x3D;True)<br>          (7): ReLU(inplace&#x3D;True)<br>        )<br>        (branch_proj): Sequential(<br>          (0): Conv2d(24, 24, kernel_size&#x3D;(3, 3), stride&#x3D;(2, 2), padding&#x3D;(1, 1), groups&#x3D;24, bias&#x3D;False)<br>          (1): BatchNorm2d(24, eps&#x3D;1e-05, momentum&#x3D;0.1, affine&#x3D;True, track_running_stats&#x3D;True)<br>          (2): Conv2d(24, 24, kernel_size&#x3D;(1, 1), stride&#x3D;(1, 1), bias&#x3D;False)<br>          (3): BatchNorm2d(24, eps&#x3D;1e-05, momentum&#x3D;0.1, affine&#x3D;True, track_running_stats&#x3D;True)<br>          (4): ReLU(inplace&#x3D;True)<br>        )<br>      )<br>      (1): ShuffleV2Block(<br>        (branch_main): Sequential(<br>          (0): Conv2d(24, 24, kernel_size&#x3D;(1, 1), stride&#x3D;(1, 1), bias&#x3D;False)<br>          (1): BatchNorm2d(24, eps&#x3D;1e-05, momentum&#x3D;0.1, affine&#x3D;True, track_running_stats&#x3D;True)<br>          (2): ReLU(inplace&#x3D;True)<br>          (3): Conv2d(24, 24, kernel_size&#x3D;(3, 3), stride&#x3D;(1, 1), padding&#x3D;(1, 1), groups&#x3D;24, bias&#x3D;False)<br>          (4): BatchNorm2d(24, eps&#x3D;1e-05, momentum&#x3D;0.1, affine&#x3D;True, track_running_stats&#x3D;True)<br>          (5): Conv2d(24, 24, kernel_size&#x3D;(1, 1), stride&#x3D;(1, 1), bias&#x3D;False)<br>          (6): BatchNorm2d(24, eps&#x3D;1e-05, momentum&#x3D;0.1, affine&#x3D;True, track_running_stats&#x3D;True)<br>          (7): ReLU(inplace&#x3D;True)<br>        )<br>      )<br>      (2): ShuffleV2Block(<br>        (branch_main): Sequential(<br>          (0): Conv2d(24, 24, kernel_size&#x3D;(1, 1), stride&#x3D;(1, 1), bias&#x3D;False)<br>          (1): BatchNorm2d(24, eps&#x3D;1e-05, momentum&#x3D;0.1, affine&#x3D;True, track_running_stats&#x3D;True)<br>          (2): ReLU(inplace&#x3D;True)<br>          (3): Conv2d(24, 24, kernel_size&#x3D;(3, 3), stride&#x3D;(1, 1), padding&#x3D;(1, 1), groups&#x3D;24, bias&#x3D;False)<br>          (4): BatchNorm2d(24, eps&#x3D;1e-05, momentum&#x3D;0.1, affine&#x3D;True, track_running_stats&#x3D;True)<br>          (5): Conv2d(24, 24, kernel_size&#x3D;(1, 1), stride&#x3D;(1, 1), bias&#x3D;False)<br>          (6): BatchNorm2d(24, eps&#x3D;1e-05, momentum&#x3D;0.1, affine&#x3D;True, track_running_stats&#x3D;True)<br>          (7): ReLU(inplace&#x3D;True)<br>        )<br>      )<br>      (3): ShuffleV2Block(<br>        (branch_main): Sequential(<br>          (0): Conv2d(24, 24, kernel_size&#x3D;(1, 1), stride&#x3D;(1, 1), bias&#x3D;False)<br>          (1): BatchNorm2d(24, eps&#x3D;1e-05, momentum&#x3D;0.1, affine&#x3D;True, track_running_stats&#x3D;True)<br>          (2): ReLU(inplace&#x3D;True)<br>          (3): Conv2d(24, 24, kernel_size&#x3D;(3, 3), stride&#x3D;(1, 1), padding&#x3D;(1, 1), groups&#x3D;24, bias&#x3D;False)<br>          (4): BatchNorm2d(24, eps&#x3D;1e-05, momentum&#x3D;0.1, affine&#x3D;True, track_running_stats&#x3D;True)<br>          (5): Conv2d(24, 24, kernel_size&#x3D;(1, 1), stride&#x3D;(1, 1), bias&#x3D;False)<br>          (6): BatchNorm2d(24, eps&#x3D;1e-05, momentum&#x3D;0.1, affine&#x3D;True, track_running_stats&#x3D;True)<br>          (7): ReLU(inplace&#x3D;True)<br>        )<br>      )<br>    )</p>
<p>​    (stage3): Sequential(<br>​      (0): ShuffleV2Block(<br>​        (branch_main): Sequential(<br>​          (0): Conv2d(48, 48, kernel_size&#x3D;(1, 1), stride&#x3D;(1, 1), bias&#x3D;False)<br>​          (1): BatchNorm2d(48, eps&#x3D;1e-05, momentum&#x3D;0.1, affine&#x3D;True, track_running_stats&#x3D;True)<br>​          (2): ReLU(inplace&#x3D;True)<br>​          (3): Conv2d(48, 48, kernel_size&#x3D;(3, 3), stride&#x3D;(2, 2), padding&#x3D;(1, 1), groups&#x3D;48, bias&#x3D;False)<br>​          (4): BatchNorm2d(48, eps&#x3D;1e-05, momentum&#x3D;0.1, affine&#x3D;True, track_running_stats&#x3D;True)<br>​          (5): Conv2d(48, 48, kernel_size&#x3D;(1, 1), stride&#x3D;(1, 1), bias&#x3D;False)<br>​          (6): BatchNorm2d(48, eps&#x3D;1e-05, momentum&#x3D;0.1, affine&#x3D;True, track_running_stats&#x3D;True)<br>​          (7): ReLU(inplace&#x3D;True)<br>​        )<br>​        (branch_proj): Sequential(<br>​          (0): Conv2d(48, 48, kernel_size&#x3D;(3, 3), stride&#x3D;(2, 2), padding&#x3D;(1, 1), groups&#x3D;48, bias&#x3D;False)<br>​          (1): BatchNorm2d(48, eps&#x3D;1e-05, momentum&#x3D;0.1, affine&#x3D;True, track_running_stats&#x3D;True)<br>​          (2): Conv2d(48, 48, kernel_size&#x3D;(1, 1), stride&#x3D;(1, 1), bias&#x3D;False)<br>​          (3): BatchNorm2d(48, eps&#x3D;1e-05, momentum&#x3D;0.1, affine&#x3D;True, track_running_stats&#x3D;True)<br>​          (4): ReLU(inplace&#x3D;True)<br>​        )<br>​      )<br>​      (1): ShuffleV2Block(<br>​        (branch_main): Sequential(<br>​          (0): Conv2d(48, 48, kernel_size&#x3D;(1, 1), stride&#x3D;(1, 1), bias&#x3D;False)<br>​          (1): BatchNorm2d(48, eps&#x3D;1e-05, momentum&#x3D;0.1, affine&#x3D;True, track_running_stats&#x3D;True)<br>​          (2): ReLU(inplace&#x3D;True)<br>​          (3): Conv2d(48, 48, kernel_size&#x3D;(3, 3), stride&#x3D;(1, 1), padding&#x3D;(1, 1), groups&#x3D;48, bias&#x3D;False)<br>​          (4): BatchNorm2d(48, eps&#x3D;1e-05, momentum&#x3D;0.1, affine&#x3D;True, track_running_stats&#x3D;True)<br>​          (5): Conv2d(48, 48, kernel_size&#x3D;(1, 1), stride&#x3D;(1, 1), bias&#x3D;False)<br>​          (6): BatchNorm2d(48, eps&#x3D;1e-05, momentum&#x3D;0.1, affine&#x3D;True, track_running_stats&#x3D;True)<br>​          (7): ReLU(inplace&#x3D;True)<br>​        )<br>​      )<br>​      (2): ShuffleV2Block(<br>​        (branch_main): Sequential(<br>​          (0): Conv2d(48, 48, kernel_size&#x3D;(1, 1), stride&#x3D;(1, 1), bias&#x3D;False)<br>​          (1): BatchNorm2d(48, eps&#x3D;1e-05, momentum&#x3D;0.1, affine&#x3D;True, track_running_stats&#x3D;True)<br>​          (2): ReLU(inplace&#x3D;True)<br>​          (3): Conv2d(48, 48, kernel_size&#x3D;(3, 3), stride&#x3D;(1, 1), padding&#x3D;(1, 1), groups&#x3D;48, bias&#x3D;False)<br>​          (4): BatchNorm2d(48, eps&#x3D;1e-05, momentum&#x3D;0.1, affine&#x3D;True, track_running_stats&#x3D;True)<br>​          (5): Conv2d(48, 48, kernel_size&#x3D;(1, 1), stride&#x3D;(1, 1), bias&#x3D;False)<br>​          (6): BatchNorm2d(48, eps&#x3D;1e-05, momentum&#x3D;0.1, affine&#x3D;True, track_running_stats&#x3D;True)<br>​          (7): ReLU(inplace&#x3D;True)<br>​        )<br>​      )<br>​      (3): ShuffleV2Block(<br>​        (branch_main): Sequential(<br>​          (0): Conv2d(48, 48, kernel_size&#x3D;(1, 1), stride&#x3D;(1, 1), bias&#x3D;False)<br>​          (1): BatchNorm2d(48, eps&#x3D;1e-05, momentum&#x3D;0.1, affine&#x3D;True, track_running_stats&#x3D;True)<br>​          (2): ReLU(inplace&#x3D;True)<br>​          (3): Conv2d(48, 48, kernel_size&#x3D;(3, 3), stride&#x3D;(1, 1), padding&#x3D;(1, 1), groups&#x3D;48, bias&#x3D;False)<br>​          (4): BatchNorm2d(48, eps&#x3D;1e-05, momentum&#x3D;0.1, affine&#x3D;True, track_running_stats&#x3D;True)<br>​          (5): Conv2d(48, 48, kernel_size&#x3D;(1, 1), stride&#x3D;(1, 1), bias&#x3D;False)<br>​          (6): BatchNorm2d(48, eps&#x3D;1e-05, momentum&#x3D;0.1, affine&#x3D;True, track_running_stats&#x3D;True)<br>​          (7): ReLU(inplace&#x3D;True)<br>​        )<br>​      )<br>​      (4): ShuffleV2Block(<br>​        (branch_main): Sequential(<br>​          (0): Conv2d(48, 48, kernel_size&#x3D;(1, 1), stride&#x3D;(1, 1), bias&#x3D;False)<br>​          (1): BatchNorm2d(48, eps&#x3D;1e-05, momentum&#x3D;0.1, affine&#x3D;True, track_running_stats&#x3D;True)<br>​          (2): ReLU(inplace&#x3D;True)<br>​          (3): Conv2d(48, 48, kernel_size&#x3D;(3, 3), stride&#x3D;(1, 1), padding&#x3D;(1, 1), groups&#x3D;48, bias&#x3D;False)<br>​          (4): BatchNorm2d(48, eps&#x3D;1e-05, momentum&#x3D;0.1, affine&#x3D;True, track_running_stats&#x3D;True)<br>​          (5): Conv2d(48, 48, kernel_size&#x3D;(1, 1), stride&#x3D;(1, 1), bias&#x3D;False)<br>​          (6): BatchNorm2d(48, eps&#x3D;1e-05, momentum&#x3D;0.1, affine&#x3D;True, track_running_stats&#x3D;True)<br>​          (7): ReLU(inplace&#x3D;True)<br>​        )<br>​      )<br>​      (5): ShuffleV2Block(<br>​        (branch_main): Sequential(<br>​          (0): Conv2d(48, 48, kernel_size&#x3D;(1, 1), stride&#x3D;(1, 1), bias&#x3D;False)<br>​          (1): BatchNorm2d(48, eps&#x3D;1e-05, momentum&#x3D;0.1, affine&#x3D;True, track_running_stats&#x3D;True)<br>​          (2): ReLU(inplace&#x3D;True)<br>​          (3): Conv2d(48, 48, kernel_size&#x3D;(3, 3), stride&#x3D;(1, 1), padding&#x3D;(1, 1), groups&#x3D;48, bias&#x3D;False)<br>​          (4): BatchNorm2d(48, eps&#x3D;1e-05, momentum&#x3D;0.1, affine&#x3D;True, track_running_stats&#x3D;True)<br>​          (5): Conv2d(48, 48, kernel_size&#x3D;(1, 1), stride&#x3D;(1, 1), bias&#x3D;False)<br>​          (6): BatchNorm2d(48, eps&#x3D;1e-05, momentum&#x3D;0.1, affine&#x3D;True, track_running_stats&#x3D;True)<br>​          (7): ReLU(inplace&#x3D;True)<br>​        )<br>​      )<br>​      (6): ShuffleV2Block(<br>​        (branch_main): Sequential(<br>​          (0): Conv2d(48, 48, kernel_size&#x3D;(1, 1), stride&#x3D;(1, 1), bias&#x3D;False)<br>​          (1): BatchNorm2d(48, eps&#x3D;1e-05, momentum&#x3D;0.1, affine&#x3D;True, track_running_stats&#x3D;True)<br>​          (2): ReLU(inplace&#x3D;True)<br>​          (3): Conv2d(48, 48, kernel_size&#x3D;(3, 3), stride&#x3D;(1, 1), padding&#x3D;(1, 1), groups&#x3D;48, bias&#x3D;False)<br>​          (4): BatchNorm2d(48, eps&#x3D;1e-05, momentum&#x3D;0.1, affine&#x3D;True, track_running_stats&#x3D;True)<br>​          (5): Conv2d(48, 48, kernel_size&#x3D;(1, 1), stride&#x3D;(1, 1), bias&#x3D;False)<br>​          (6): BatchNorm2d(48, eps&#x3D;1e-05, momentum&#x3D;0.1, affine&#x3D;True, track_running_stats&#x3D;True)<br>​          (7): ReLU(inplace&#x3D;True)<br>​        )<br>​      )<br>​      (7): ShuffleV2Block(<br>​        (branch_main): Sequential(<br>​          (0): Conv2d(48, 48, kernel_size&#x3D;(1, 1), stride&#x3D;(1, 1), bias&#x3D;False)<br>​          (1): BatchNorm2d(48, eps&#x3D;1e-05, momentum&#x3D;0.1, affine&#x3D;True, track_running_stats&#x3D;True)<br>​          (2): ReLU(inplace&#x3D;True)<br>​          (3): Conv2d(48, 48, kernel_size&#x3D;(3, 3), stride&#x3D;(1, 1), padding&#x3D;(1, 1), groups&#x3D;48, bias&#x3D;False)<br>​          (4): BatchNorm2d(48, eps&#x3D;1e-05, momentum&#x3D;0.1, affine&#x3D;True, track_running_stats&#x3D;True)<br>​          (5): Conv2d(48, 48, kernel_size&#x3D;(1, 1), stride&#x3D;(1, 1), bias&#x3D;False)<br>​          (6): BatchNorm2d(48, eps&#x3D;1e-05, momentum&#x3D;0.1, affine&#x3D;True, track_running_stats&#x3D;True)<br>​          (7): ReLU(inplace&#x3D;True)<br>​        )<br>​      )<br>​    )</p>
<p>​    (stage4): Sequential(<br>​      (0): ShuffleV2Block(<br>​        (branch_main): Sequential(<br>​          (0): Conv2d(96, 96, kernel_size&#x3D;(1, 1), stride&#x3D;(1, 1), bias&#x3D;False)<br>​          (1): BatchNorm2d(96, eps&#x3D;1e-05, momentum&#x3D;0.1, affine&#x3D;True, track_running_stats&#x3D;True)<br>​          (2): ReLU(inplace&#x3D;True)<br>​          (3): Conv2d(96, 96, kernel_size&#x3D;(3, 3), stride&#x3D;(2, 2), padding&#x3D;(1, 1), groups&#x3D;96, bias&#x3D;False)<br>​          (4): BatchNorm2d(96, eps&#x3D;1e-05, momentum&#x3D;0.1, affine&#x3D;True, track_running_stats&#x3D;True)<br>​          (5): Conv2d(96, 96, kernel_size&#x3D;(1, 1), stride&#x3D;(1, 1), bias&#x3D;False)<br>​          (6): BatchNorm2d(96, eps&#x3D;1e-05, momentum&#x3D;0.1, affine&#x3D;True, track_running_stats&#x3D;True)<br>​          (7): ReLU(inplace&#x3D;True)<br>​        )<br>​        (branch_proj): Sequential(<br>​          (0): Conv2d(96, 96, kernel_size&#x3D;(3, 3), stride&#x3D;(2, 2), padding&#x3D;(1, 1), groups&#x3D;96, bias&#x3D;False)<br>​          (1): BatchNorm2d(96, eps&#x3D;1e-05, momentum&#x3D;0.1, affine&#x3D;True, track_running_stats&#x3D;True)<br>​          (2): Conv2d(96, 96, kernel_size&#x3D;(1, 1), stride&#x3D;(1, 1), bias&#x3D;False)<br>​          (3): BatchNorm2d(96, eps&#x3D;1e-05, momentum&#x3D;0.1, affine&#x3D;True, track_running_stats&#x3D;True)<br>​          (4): ReLU(inplace&#x3D;True)<br>​        )<br>​      )<br>​      (1): ShuffleV2Block(<br>​        (branch_main): Sequential(<br>​          (0): Conv2d(96, 96, kernel_size&#x3D;(1, 1), stride&#x3D;(1, 1), bias&#x3D;False)<br>​          (1): BatchNorm2d(96, eps&#x3D;1e-05, momentum&#x3D;0.1, affine&#x3D;True, track_running_stats&#x3D;True)<br>​          (2): ReLU(inplace&#x3D;True)<br>​          (3): Conv2d(96, 96, kernel_size&#x3D;(3, 3), stride&#x3D;(1, 1), padding&#x3D;(1, 1), groups&#x3D;96, bias&#x3D;False)<br>​          (4): BatchNorm2d(96, eps&#x3D;1e-05, momentum&#x3D;0.1, affine&#x3D;True, track_running_stats&#x3D;True)<br>​          (5): Conv2d(96, 96, kernel_size&#x3D;(1, 1), stride&#x3D;(1, 1), bias&#x3D;False)<br>​          (6): BatchNorm2d(96, eps&#x3D;1e-05, momentum&#x3D;0.1, affine&#x3D;True, track_running_stats&#x3D;True)<br>​          (7): ReLU(inplace&#x3D;True)<br>​        )<br>​      )<br>​      (2): ShuffleV2Block(<br>​        (branch_main): Sequential(<br>​          (0): Conv2d(96, 96, kernel_size&#x3D;(1, 1), stride&#x3D;(1, 1), bias&#x3D;False)<br>​          (1): BatchNorm2d(96, eps&#x3D;1e-05, momentum&#x3D;0.1, affine&#x3D;True, track_running_stats&#x3D;True)<br>​          (2): ReLU(inplace&#x3D;True)<br>​          (3): Conv2d(96, 96, kernel_size&#x3D;(3, 3), stride&#x3D;(1, 1), padding&#x3D;(1, 1), groups&#x3D;96, bias&#x3D;False)<br>​          (4): BatchNorm2d(96, eps&#x3D;1e-05, momentum&#x3D;0.1, affine&#x3D;True, track_running_stats&#x3D;True)<br>​          (5): Conv2d(96, 96, kernel_size&#x3D;(1, 1), stride&#x3D;(1, 1), bias&#x3D;False)<br>​          (6): BatchNorm2d(96, eps&#x3D;1e-05, momentum&#x3D;0.1, affine&#x3D;True, track_running_stats&#x3D;True)<br>​          (7): ReLU(inplace&#x3D;True)<br>​        )<br>​      )<br>​      (3): ShuffleV2Block(<br>​        (branch_main): Sequential(<br>​          (0): Conv2d(96, 96, kernel_size&#x3D;(1, 1), stride&#x3D;(1, 1), bias&#x3D;False)<br>​          (1): BatchNorm2d(96, eps&#x3D;1e-05, momentum&#x3D;0.1, affine&#x3D;True, track_running_stats&#x3D;True)<br>​          (2): ReLU(inplace&#x3D;True)<br>​          (3): Conv2d(96, 96, kernel_size&#x3D;(3, 3), stride&#x3D;(1, 1), padding&#x3D;(1, 1), groups&#x3D;96, bias&#x3D;False)<br>​          (4): BatchNorm2d(96, eps&#x3D;1e-05, momentum&#x3D;0.1, affine&#x3D;True, track_running_stats&#x3D;True)<br>​          (5): Conv2d(96, 96, kernel_size&#x3D;(1, 1), stride&#x3D;(1, 1), bias&#x3D;False)<br>​          (6): BatchNorm2d(96, eps&#x3D;1e-05, momentum&#x3D;0.1, affine&#x3D;True, track_running_stats&#x3D;True)<br>​          (7): ReLU(inplace&#x3D;True)<br>​        )<br>​      )<br>​    )<br>  )<br>  (fpn): LightFPN(<br>​    (head_2): DWConvblock(<br>​      (block): Sequential(<br>​        (0): Conv2d(288, 112, kernel_size&#x3D;(1, 1), stride&#x3D;(1, 1), bias&#x3D;False)<br>​        (1): BatchNorm2d(112, eps&#x3D;1e-05, momentum&#x3D;0.1, affine&#x3D;True, track_running_stats&#x3D;True)<br>​        (2): ReLU(inplace&#x3D;True)<br>​        (3): Conv2d(112, 112, kernel_size&#x3D;(5, 5), stride&#x3D;(1, 1), padding&#x3D;(2, 2), groups&#x3D;112, bias&#x3D;False)<br>​        (4): BatchNorm2d(112, eps&#x3D;1e-05, momentum&#x3D;0.1, affine&#x3D;True, track_running_stats&#x3D;True)<br>​        (5): ReLU(inplace&#x3D;True)<br>​        (6): Conv2d(112, 56, kernel_size&#x3D;(1, 1), stride&#x3D;(1, 1), bias&#x3D;False)<br>​        (7): BatchNorm2d(56, eps&#x3D;1e-05, momentum&#x3D;0.1, affine&#x3D;True, track_running_stats&#x3D;True)<br>​        (8): Conv2d(56, 56, kernel_size&#x3D;(5, 5), stride&#x3D;(1, 1), padding&#x3D;(2, 2), groups&#x3D;56, bias&#x3D;False)<br>​        (9): BatchNorm2d(56, eps&#x3D;1e-05, momentum&#x3D;0.1, affine&#x3D;True, track_running_stats&#x3D;True)<br>​        (10): ReLU(inplace&#x3D;True)<br>​        (11): Conv2d(56, 112, kernel_size&#x3D;(1, 1), stride&#x3D;(1, 1), bias&#x3D;False)<br>​        (12): BatchNorm2d(112, eps&#x3D;1e-05, momentum&#x3D;0.1, affine&#x3D;True, track_running_stats&#x3D;True)<br>​      )<br>​    )<br>​    (head_3): DWConvblock(<br>​      (block): Sequential(<br>​        (0): Conv2d(192, 112, kernel_size&#x3D;(1, 1), stride&#x3D;(1, 1), bias&#x3D;False)<br>​        (1): BatchNorm2d(112, eps&#x3D;1e-05, momentum&#x3D;0.1, affine&#x3D;True, track_running_stats&#x3D;True)<br>​        (2): ReLU(inplace&#x3D;True)<br>​        (3): Conv2d(112, 112, kernel_size&#x3D;(5, 5), stride&#x3D;(1, 1), padding&#x3D;(2, 2), groups&#x3D;112, bias&#x3D;False)<br>​        (4): BatchNorm2d(112, eps&#x3D;1e-05, momentum&#x3D;0.1, affine&#x3D;True, track_running_stats&#x3D;True)<br>​        (5): ReLU(inplace&#x3D;True)<br>​        (6): Conv2d(112, 56, kernel_size&#x3D;(1, 1), stride&#x3D;(1, 1), bias&#x3D;False)<br>​        (7): BatchNorm2d(56, eps&#x3D;1e-05, momentum&#x3D;0.1, affine&#x3D;True, track_running_stats&#x3D;True)<br>​        (8): Conv2d(56, 56, kernel_size&#x3D;(5, 5), stride&#x3D;(1, 1), padding&#x3D;(2, 2), groups&#x3D;56, bias&#x3D;False)<br>​        (9): BatchNorm2d(56, eps&#x3D;1e-05, momentum&#x3D;0.1, affine&#x3D;True, track_running_stats&#x3D;True)<br>​        (10): ReLU(inplace&#x3D;True)<br>​        (11): Conv2d(56, 112, kernel_size&#x3D;(1, 1), stride&#x3D;(1, 1), bias&#x3D;False)<br>​        (12): BatchNorm2d(112, eps&#x3D;1e-05, momentum&#x3D;0.1, affine&#x3D;True, track_running_stats&#x3D;True)<br>​      )<br>​    )<br>  )<br>  (output_layers): Conv2d(112, 24, kernel_size&#x3D;(1, 1), stride&#x3D;(1, 1))<br>)</p>
<hr>
<pre><code>    Layer (type)               Output Shape         Param #
</code></pre>
<p>&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;<br>            Conv2d-1         [-1, 24, 240, 320]             648<br>       BatchNorm2d-2         [-1, 24, 240, 320]              48<br>              ReLU-3         [-1, 24, 240, 320]               0<br>         MaxPool2d-4         [-1, 24, 120, 160]               0<br>stage2{<br>1ShuffleV2Block<br>(branch_main):<br>           Conv2d-5           [-1, 24, 60, 80]             216<br>      BatchNorm2d-6           [-1, 24, 60, 80]              48<br>           Conv2d-7           [-1, 24, 60, 80]             576<br>      BatchNorm2d-8           [-1, 24, 60, 80]              48<br>             ReLU-9           [-1, 24, 60, 80]               0<br>          Conv2d-10         [-1, 24, 120, 160]             576<br>     BatchNorm2d-11         [-1, 24, 120, 160]              48<br>            ReLU-12         [-1, 24, 120, 160]               0<br>(branch_proj)<br>          Conv2d-13           [-1, 24, 60, 80]             216<br>     BatchNorm2d-14           [-1, 24, 60, 80]              48<br>          Conv2d-15           [-1, 24, 60, 80]             576<br>     BatchNorm2d-16           [-1, 24, 60, 80]              48<br>            ReLU-17           [-1, 24, 60, 80]               0</p>
<p>2ShuffleV2Block-18           [-1, 48, 60, 80]               0<br>   (branch_main):<br>           Conv2d-19           [-1, 24, 60, 80]             576<br>      BatchNorm2d-20           [-1, 24, 60, 80]              48<br>             ReLU-21           [-1, 24, 60, 80]               0<br>           Conv2d-22           [-1, 24, 60, 80]             216<br>      BatchNorm2d-23           [-1, 24, 60, 80]              48<br>           Conv2d-24           [-1, 24, 60, 80]             576<br>      BatchNorm2d-25           [-1, 24, 60, 80]              48<br>             ReLU-26           [-1, 24, 60, 80]               0</p>
<p>3ShuffleV2Block-27           [-1, 48, 60, 80]               0<br> (branch_main):<br>           Conv2d-28           [-1, 24, 60, 80]             576<br>      BatchNorm2d-29           [-1, 24, 60, 80]              48<br>             ReLU-30           [-1, 24, 60, 80]               0<br>           Conv2d-31           [-1, 24, 60, 80]             216<br>      BatchNorm2d-32           [-1, 24, 60, 80]              48<br>           Conv2d-33           [-1, 24, 60, 80]             576<br>      BatchNorm2d-34           [-1, 24, 60, 80]              48<br>             ReLU-35           [-1, 24, 60, 80]               0</p>
<p>4ShuffleV2Block-36           [-1, 48, 60, 80]               0<br> (branch_main):<br>           Conv2d-37           [-1, 24, 60, 80]             576<br>      BatchNorm2d-38           [-1, 24, 60, 80]              48<br>             ReLU-39           [-1, 24, 60, 80]               0<br>           Conv2d-40           [-1, 24, 60, 80]             216<br>      BatchNorm2d-41           [-1, 24, 60, 80]              48<br>           Conv2d-42           [-1, 24, 60, 80]             576<br>      BatchNorm2d-43           [-1, 24, 60, 80]              48<br>             ReLU-44           [-1, 24, 60, 80]               0<br>}</p>
<p>stage3{<br>1ShuffleV2Block-45           [-1, 48, 60, 80]               0<br> (branch_main):<br>           Conv2d-46           [-1, 48, 30, 40]             432<br>      BatchNorm2d-47           [-1, 48, 30, 40]              96<br>           Conv2d-48           [-1, 48, 30, 40]           2,304<br>      BatchNorm2d-49           [-1, 48, 30, 40]              96<br>             ReLU-50           [-1, 48, 30, 40]               0<br>           Conv2d-51           [-1, 48, 60, 80]           2,304<br>      BatchNorm2d-52           [-1, 48, 60, 80]              96<br>             ReLU-53           [-1, 48, 60, 80]               0<br>(branch_proj):<br>           Conv2d-54           [-1, 48, 30, 40]             432<br>      BatchNorm2d-55           [-1, 48, 30, 40]              96<br>           Conv2d-56           [-1, 48, 30, 40]           2,304<br>      BatchNorm2d-57           [-1, 48, 30, 40]              96<br>             ReLU-58           [-1, 48, 30, 40]               0<br>2ShuffleV2Block-59           [-1, 96, 30, 40]               0<br> (branch_main):<br>           Conv2d-60           [-1, 48, 30, 40]           2,304<br>      BatchNorm2d-61           [-1, 48, 30, 40]              96<br>             ReLU-62           [-1, 48, 30, 40]               0<br>           Conv2d-63           [-1, 48, 30, 40]             432<br>      BatchNorm2d-64           [-1, 48, 30, 40]              96<br>           Conv2d-65           [-1, 48, 30, 40]           2,304<br>      BatchNorm2d-66           [-1, 48, 30, 40]              96<br>             ReLU-67           [-1, 48, 30, 40]               0<br>3ShuffleV2Block-68           [-1, 96, 30, 40]               0<br> (branch_main):<br>           Conv2d-69           [-1, 48, 30, 40]           2,304<br>      BatchNorm2d-70           [-1, 48, 30, 40]              96<br>             ReLU-71           [-1, 48, 30, 40]               0<br>           Conv2d-72           [-1, 48, 30, 40]             432<br>      BatchNorm2d-73           [-1, 48, 30, 40]              96<br>           Conv2d-74           [-1, 48, 30, 40]           2,304<br>      BatchNorm2d-75           [-1, 48, 30, 40]              96<br>             ReLU-76           [-1, 48, 30, 40]               0<br>4ShuffleV2Block-77           [-1, 96, 30, 40]               0<br> (branch_main):<br>           Conv2d-78           [-1, 48, 30, 40]           2,304<br>      BatchNorm2d-79           [-1, 48, 30, 40]              96<br>             ReLU-80           [-1, 48, 30, 40]               0<br>           Conv2d-81           [-1, 48, 30, 40]             432<br>      BatchNorm2d-82           [-1, 48, 30, 40]              96<br>           Conv2d-83           [-1, 48, 30, 40]           2,304<br>      BatchNorm2d-84           [-1, 48, 30, 40]              96<br>             ReLU-85           [-1, 48, 30, 40]               0<br>5ShuffleV2Block-86           [-1, 96, 30, 40]               0<br> (branch_main):<br>           Conv2d-87           [-1, 48, 30, 40]           2,304<br>      BatchNorm2d-88           [-1, 48, 30, 40]              96<br>             ReLU-89           [-1, 48, 30, 40]               0<br>           Conv2d-90           [-1, 48, 30, 40]             432<br>      BatchNorm2d-91           [-1, 48, 30, 40]              96<br>           Conv2d-92           [-1, 48, 30, 40]           2,304<br>      BatchNorm2d-93           [-1, 48, 30, 40]              96<br>             ReLU-94           [-1, 48, 30, 40]               0<br>6ShuffleV2Block-95           [-1, 96, 30, 40]               0<br> (branch_main):<br>           Conv2d-96           [-1, 48, 30, 40]           2,304<br>      BatchNorm2d-97           [-1, 48, 30, 40]              96<br>             ReLU-98           [-1, 48, 30, 40]               0<br>           Conv2d-99           [-1, 48, 30, 40]             432<br>     BatchNorm2d-100           [-1, 48, 30, 40]              96<br>          Conv2d-101           [-1, 48, 30, 40]           2,304<br>     BatchNorm2d-102           [-1, 48, 30, 40]              96<br>            ReLU-103           [-1, 48, 30, 40]               0<br>7ShuffleV2Block-104           [-1, 96, 30, 40]               0<br> (branch_main):<br>          Conv2d-105           [-1, 48, 30, 40]           2,304<br>     BatchNorm2d-106           [-1, 48, 30, 40]              96<br>            ReLU-107           [-1, 48, 30, 40]               0<br>          Conv2d-108           [-1, 48, 30, 40]             432<br>     BatchNorm2d-109           [-1, 48, 30, 40]              96<br>          Conv2d-110           [-1, 48, 30, 40]           2,304<br>     BatchNorm2d-111           [-1, 48, 30, 40]              96<br>            ReLU-112           [-1, 48, 30, 40]               0<br>8ShuffleV2Block-113           [-1, 96, 30, 40]               0<br> (branch_main):<br>          Conv2d-114           [-1, 48, 30, 40]           2,304<br>     BatchNorm2d-115           [-1, 48, 30, 40]              96<br>            ReLU-116           [-1, 48, 30, 40]               0<br>          Conv2d-117           [-1, 48, 30, 40]             432<br>     BatchNorm2d-118           [-1, 48, 30, 40]              96<br>          Conv2d-119           [-1, 48, 30, 40]           2,304<br>     BatchNorm2d-120           [-1, 48, 30, 40]              96<br>            ReLU-121           [-1, 48, 30, 40]               0<br>}</p>
<p>stage4{<br>1ShuffleV2Block-122           [-1, 96, 30, 40]               0<br> (branch_main):<br>          Conv2d-123           [-1, 96, 15, 20]             864<br>     BatchNorm2d-124           [-1, 96, 15, 20]             192<br>          Conv2d-125           [-1, 96, 15, 20]           9,216<br>     BatchNorm2d-126           [-1, 96, 15, 20]             192<br>            ReLU-127           [-1, 96, 15, 20]               0<br>          Conv2d-128           [-1, 96, 30, 40]           9,216<br>     BatchNorm2d-129           [-1, 96, 30, 40]             192<br>            ReLU-130           [-1, 96, 30, 40]               0<br>(branch_proj):<br>          Conv2d-131           [-1, 96, 15, 20]             864<br>     BatchNorm2d-132           [-1, 96, 15, 20]             192<br>          Conv2d-133           [-1, 96, 15, 20]           9,216<br>     BatchNorm2d-134           [-1, 96, 15, 20]             192<br>            ReLU-135           [-1, 96, 15, 20]               0<br>2ShuffleV2Block-136          [-1, 192, 15, 20]               0<br>(branch_main):<br>          Conv2d-137           [-1, 96, 15, 20]           9,216<br>     BatchNorm2d-138           [-1, 96, 15, 20]             192<br>            ReLU-139           [-1, 96, 15, 20]               0<br>          Conv2d-140           [-1, 96, 15, 20]             864<br>     BatchNorm2d-141           [-1, 96, 15, 20]             192<br>          Conv2d-142           [-1, 96, 15, 20]           9,216<br>     BatchNorm2d-143           [-1, 96, 15, 20]             192<br>            ReLU-144           [-1, 96, 15, 20]               0<br>3ShuffleV2Block-145          [-1, 192, 15, 20]               0<br>(branch_main):<br>          Conv2d-146           [-1, 96, 15, 20]           9,216<br>     BatchNorm2d-147           [-1, 96, 15, 20]             192<br>            ReLU-148           [-1, 96, 15, 20]               0<br>          Conv2d-149           [-1, 96, 15, 20]             864<br>     BatchNorm2d-150           [-1, 96, 15, 20]             192<br>          Conv2d-151           [-1, 96, 15, 20]           9,216<br>     BatchNorm2d-152           [-1, 96, 15, 20]             192<br>            ReLU-153           [-1, 96, 15, 20]               0<br>4ShuffleV2Block-154          [-1, 192, 15, 20]               0<br>(branch_main):<br>          Conv2d-155           [-1, 96, 15, 20]           9,216<br>     BatchNorm2d-156           [-1, 96, 15, 20]             192<br>            ReLU-157           [-1, 96, 15, 20]               0<br>          Conv2d-158           [-1, 96, 15, 20]             864<br>     BatchNorm2d-159           [-1, 96, 15, 20]             192<br>          Conv2d-160           [-1, 96, 15, 20]           9,216<br>     BatchNorm2d-161           [-1, 96, 15, 20]             192<br>            ReLU-162           [-1, 96, 15, 20]               0</p>
<p>ShuffleV2Block-163          [-1, 192, 15, 20]               0<br>ShuffleNetV2-164  [[-1, 96, 30, 40], [-1, 192, 15, 20]]               0<br>          Conv2d-165          [-1, 112, 15, 20]          21,504<br>     BatchNorm2d-166          [-1, 112, 15, 20]             224<br>            ReLU-167          [-1, 112, 15, 20]               0<br>          Conv2d-168          [-1, 112, 15, 20]           2,800<br>     BatchNorm2d-169          [-1, 112, 15, 20]             224<br>            ReLU-170          [-1, 112, 15, 20]               0<br>          Conv2d-171           [-1, 56, 15, 20]           6,272<br>     BatchNorm2d-172           [-1, 56, 15, 20]             112<br>          Conv2d-173           [-1, 56, 15, 20]           1,400<br>     BatchNorm2d-174           [-1, 56, 15, 20]             112<br>            ReLU-175           [-1, 56, 15, 20]               0<br>          Conv2d-176          [-1, 112, 15, 20]           6,272<br>     BatchNorm2d-177          [-1, 112, 15, 20]             224<br>DWConvblock-178          [-1, 112, 15, 20]               0（向上）</p>
<pre><code>      Conv2d-179          [-1, 112, 30, 40]          32,256
 BatchNorm2d-180          [-1, 112, 30, 40]             224
        ReLU-181          [-1, 112, 30, 40]               0
      Conv2d-182          [-1, 112, 30, 40]           2,800
 BatchNorm2d-183          [-1, 112, 30, 40]             224
        ReLU-184          [-1, 112, 30, 40]               0
      Conv2d-185           [-1, 56, 30, 40]           6,272
 BatchNorm2d-186           [-1, 56, 30, 40]             112
      Conv2d-187           [-1, 56, 30, 40]           1,400
 BatchNorm2d-188           [-1, 56, 30, 40]             112
        ReLU-189           [-1, 56, 30, 40]               0
      Conv2d-190          [-1, 112, 30, 40]           6,272
 BatchNorm2d-191          [-1, 112, 30, 40]             224
</code></pre>
<p>DWConvblock-192          [-1, 112, 30, 40]               0<br>LightFPN-193  [[-1, 112, 30, 40], [-1, 112, 15, 20]]               0<br>          Conv2d-194           [-1, 24, 30, 40]           2,712</p>
<pre><code>      Conv2d-195           [-1, 24, 15, 20]           2,712
</code></pre>
<h2 id="Total-params-237-600Trainable-params-237-600Non-trainable-params-0"><a href="#Total-params-237-600Trainable-params-237-600Non-trainable-params-0" class="headerlink" title="&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;Total params: 237,600Trainable params: 237,600Non-trainable params: 0"></a>&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;<br>Total params: 237,600<br>Trainable params: 237,600<br>Non-trainable params: 0</h2><h2 id="Input-size-MB-3-52Forward-backward-pass-size-MB-13387-23Params-size-MB-0-91Estimated-Total-Size-MB-13391-65"><a href="#Input-size-MB-3-52Forward-backward-pass-size-MB-13387-23Params-size-MB-0-91Estimated-Total-Size-MB-13391-65" class="headerlink" title="Input size (MB): 3.52Forward&#x2F;backward pass size (MB): 13387.23Params size (MB): 0.91Estimated Total Size (MB): 13391.65"></a>Input size (MB): 3.52<br>Forward&#x2F;backward pass size (MB): 13387.23<br>Params size (MB): 0.91<br>Estimated Total Size (MB): 13391.65</h2><h1 id="Layer-type-depth-idx-Output-Shape-Param"><a href="#Layer-type-depth-idx-Output-Shape-Param" class="headerlink" title="&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;Layer (type:depth-idx)                        Output Shape              Param #"></a>&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;<br>Layer (type:depth-idx)                        Output Shape              Param #</h1><p>Detector                                      [1, 24, 40, 30]           –<br>├─ShuffleNetV2: 1-1                           [1, 96, 40, 30]           –<br>│    └─Sequential: 2-1                        [1, 24, 320, 240]         –<br>│    │    └─Conv2d: 3-1                       [1, 24, 320, 240]         648<br>│    │    └─BatchNorm2d: 3-2                  [1, 24, 320, 240]         48<br>│    │    └─ReLU: 3-3                         [1, 24, 320, 240]         –<br>│    └─MaxPool2d: 2-2                         [1, 24, 160, 120]         –<br>│    └─Sequential: 2-3                        [1, 48, 80, 60]           –<br>│    │    └─ShuffleV2Block: 3-4               [1, 48, 80, 60]           2,400<br>│    │    └─ShuffleV2Block: 3-5               [1, 48, 80, 60]           1,512<br>│    │    └─ShuffleV2Block: 3-6               [1, 48, 80, 60]           1,512<br>│    │    └─ShuffleV2Block: 3-7               [1, 48, 80, 60]           1,512<br>│    └─Sequential: 2-4                        [1, 96, 40, 30]           –<br>│    │    └─ShuffleV2Block: 3-8               [1, 96, 40, 30]           8,256<br>│    │    └─ShuffleV2Block: 3-9               [1, 96, 40, 30]           5,328<br>│    │    └─ShuffleV2Block: 3-10              [1, 96, 40, 30]           5,328<br>│    │    └─ShuffleV2Block: 3-11              [1, 96, 40, 30]           5,328<br>│    │    └─ShuffleV2Block: 3-12              [1, 96, 40, 30]           5,328<br>│    │    └─ShuffleV2Block: 3-13              [1, 96, 40, 30]           5,328<br>│    │    └─ShuffleV2Block: 3-14              [1, 96, 40, 30]           5,328<br>│    │    └─ShuffleV2Block: 3-15              [1, 96, 40, 30]           5,328<br>│    └─Sequential: 2-5                        [1, 192, 20, 15]          –<br>│    │    └─ShuffleV2Block: 3-16              [1, 192, 20, 15]          30,336<br>│    │    └─ShuffleV2Block: 3-17              [1, 192, 20, 15]          19,872<br>│    │    └─ShuffleV2Block: 3-18              [1, 192, 20, 15]          19,872<br>│    │    └─ShuffleV2Block: 3-19              [1, 192, 20, 15]          19,872<br>├─LightFPN: 1-2                               [1, 112, 40, 30]          –<br>│    └─DWConvblock: 2-6                       [1, 112, 20, 15]          –<br>│    │    └─Sequential: 3-20                  [1, 112, 20, 15]          39,144<br>│    └─DWConvblock: 2-7                       [1, 112, 40, 30]          –<br>│    │    └─Sequential: 3-21                  [1, 112, 40, 30]          49,896<br>├─Conv2d: 1-3                                 [1, 24, 40, 30]           2,712</p>
<h1 id="├─Conv2d-1-4-1-24-20-15-recursive"><a href="#├─Conv2d-1-4-1-24-20-15-recursive" class="headerlink" title="├─Conv2d: 1-4                                 [1, 24, 20, 15]           (recursive)"></a>├─Conv2d: 1-4                                 [1, 24, 20, 15]           (recursive)</h1><h1 id="Total-params-234-888Trainable-params-234-888Non-trainable-params-0Total-mult-adds-M-256-91"><a href="#Total-params-234-888Trainable-params-234-888Non-trainable-params-0Total-mult-adds-M-256-91" class="headerlink" title="Total params: 234,888Trainable params: 234,888Non-trainable params: 0Total mult-adds (M): 256.91"></a>Total params: 234,888<br>Trainable params: 234,888<br>Non-trainable params: 0<br>Total mult-adds (M): 256.91</h1><p>Input size (MB): 3.69<br>Forward&#x2F;backward pass size (MB): 106.43<br>Params size (MB): 0.94<br>Estimated Total Size (MB): 111.05</p>
<p>改进yolo-fastestv2</p>
<p>部署到pynq-z2上(不管用什么方法，直接用vitis ai来调用DPU)</p>
<p>分情况：如果知识调用DPU，那肯</p>
<h1 id="目的"><a href="#目的" class="headerlink" title="目的"></a>目的</h1><p>高精度和更快的检测速度</p>
<p>end-to-end recognition，硬件部署，实时检测和识别挑战</p>
<p>目前的研究趋势是构建计算效率高的轻量级模型</p>
<h1 id="Efficient-mobile-network（Emobile-Net）"><a href="#Efficient-mobile-network（Emobile-Net）" class="headerlink" title="Efficient mobile network（Emobile Net）"></a>Efficient mobile network（Emobile Net）</h1><p>高校移动网络，通常作为主干网络</p>
<h1 id="Spatial-pyramid-pooling-fast（SPPF）"><a href="#Spatial-pyramid-pooling-fast（SPPF）" class="headerlink" title="Spatial pyramid pooling-fast（SPPF）"></a>Spatial pyramid pooling-fast（SPPF）</h1><h1 id="DERT"><a href="#DERT" class="headerlink" title="DERT"></a>DERT</h1><p>改进RT-DETR</p>
<h1 id="注意机制-attention-mechanism"><a href="#注意机制-attention-mechanism" class="headerlink" title="注意机制 attention mechanism"></a>注意机制 attention mechanism</h1><p>改进cnn在图像特征密度较高的区域的特征。yolov5中集成CBAM增加细胞图像中细胞密集区域的权重，利于网络抵抗细胞以外信息的能力。</p>
<h2 id="CBAM"><a href="#CBAM" class="headerlink" title="CBAM"></a>CBAM</h2><p>CBAM（convolutional block attention module）是一种简单有效的注意力模块<sup>[1]</sup>。</p>
<hr>
<p>transformer encoder block 以及convolutional block attention module (CBAM)可以用来实现注意力机制。在血细胞图像中CBAM增加了细胞密集区域的权重。在处理上下特征数据时，transformer encoder block开源改进网络捕获细胞特性细节的能力。改进的模型开源在细胞密集区域识别和区分细胞。</p>
<img src="image-20240524104530121.png" alt="image-20240524104530121" />

<img src="/image-20240524104555281.png" alt="image-20240524104555281" />





  



<hr>
<h2 id="References"><a href="#References" class="headerlink" title="References"></a>References</h2><h1 id="HVAM-horizontal-vertical-attention-mechanism"><a href="#HVAM-horizontal-vertical-attention-mechanism" class="headerlink" title="HVAM-horizontal vertical attention mechanism"></a>HVAM-horizontal vertical attention mechanism</h1><p>水平垂直注意力机制</p>
<h1 id="transformer-encoder-block"><a href="#transformer-encoder-block" class="headerlink" title="transformer encoder block"></a>transformer encoder block</h1><p>在yolov5对上下特征数据的处理中加入了 transformer encoder block</p>
<h1 id="Omnidimensional-convolution"><a href="#Omnidimensional-convolution" class="headerlink" title="Omnidimensional convolution"></a>Omnidimensional convolution</h1><p>Use Omindimensional Dynamic Convolution (ODConv) (Li et al., 2022b) to replace the traditional downsampling convolutional layer, which enhances the backbone’s capability to generate more features. 增强骨干网络产生更多特征的能力。</p>
<p>研究了将ODConv融合到YOLOv5s的不同层中。他们的研究发现在更浅的层中部署ODConv可以得到更大的精度增益和更少的参数增量。</p>
<h2 id="Ref"><a href="#Ref" class="headerlink" title="Ref"></a>Ref</h2><p>Cheng S, Zhu Y, Wu S. Deep learning based efficient ship detection from drone-captured images for maritime surveillance[J]. Ocean Engineering, 2023, 285: 115440.</p>
<p>Li,C., Zhou, A., Yao, A., 2022b. Omni-dimensional dynamic convolution. In: International Conference on Learning Representations. URL: <a target="_blank" rel="noopener" href="https://openreview.net/forum?id=DmpCfq6Mg39">https://openreview.net/forum?id=DmpCfq6Mg39</a>.</p>
<h1 id="ConvNeXt块替换C3块"><a href="#ConvNeXt块替换C3块" class="headerlink" title="ConvNeXt块替换C3块"></a>ConvNeXt块替换C3块</h1><p>提高检测速度，但是精度略有下降</p>
<p>研究了在YOLOv5s的不同层中融合ConvNeXt块的问题，选择在第六层用ConvNeXt替换原来的C3</p>
<h2 id="Ref-1"><a href="#Ref-1" class="headerlink" title="Ref"></a>Ref</h2><p>Cheng S, Zhu Y, Wu S. Deep learning based efficient ship detection from drone-captured images for maritime surveillance[J]. Ocean Engineering, 2023, 285: 115440.</p>
<p>Liu, Z., Mao, H., Wu, C.Y., Feichtenhofer, C., Darrell, T., Xie, S., 2022. A ConvNet for the 2020s. In: Proceedings of the IEEE&#x2F;CVF Conference on Computer Vision and Pattern Recognition. CVPR, pp. 11976–11986.</p>
<h1 id="Dilated-Convolution"><a href="#Dilated-Convolution" class="headerlink" title="Dilated Convolution"></a>Dilated Convolution</h1><p>扩张性卷积用于增加主干网络的感受野</p>
<h1 id="Depthwise-Separable-Convolution-method"><a href="#Depthwise-Separable-Convolution-method" class="headerlink" title="Depthwise Separable Convolution method"></a>Depthwise Separable Convolution method</h1><p>深度可分离卷积方法用来最小化检测器的参数</p>
<h1 id="Swish-activation-function"><a href="#Swish-activation-function" class="headerlink" title="Swish activation function"></a>Swish activation function</h1><p>增强性能</p>
<h1 id="Distance-Intersection-over-Union"><a href="#Distance-Intersection-over-Union" class="headerlink" title="Distance Intersection over Union"></a>Distance Intersection over Union</h1><p>改进损失函数</p>
<h1 id="Compound-scaling"><a href="#Compound-scaling" class="headerlink" title="Compound scaling"></a>Compound scaling</h1><p>增加神经网络的深度是最常见的提高准确率的方法，但存在梯度不稳定问题。</p>
<p>宽网络倾向于寻找低级特征，不具备提取高级特征的能力。</p>
<p>复合缩放：深度、宽度、分辨率按照一定的比例变化。</p>
<h1 id="GIoU"><a href="#GIoU" class="headerlink" title="GIoU"></a>GIoU</h1><h2 id="方法"><a href="#方法" class="headerlink" title="方法"></a>方法</h2><h3 id="色彩变幻"><a href="#色彩变幻" class="headerlink" title="色彩变幻"></a>色彩变幻</h3><p>适应不同亮度环境</p>
<p>模型基于Yolo-Fastv2</p>
<p>数据集BCCD</p>
<p>主干网络</p>
<p>坐标注意力机制…….</p>
<p>颈部网络</p>
<h1 id="数据增强"><a href="#数据增强" class="headerlink" title="数据增强"></a>数据增强</h1><p>马赛克数据增强</p>
<h1 id="结果"><a href="#结果" class="headerlink" title="结果"></a>结果</h1><p>Loss-Epoch曲线图</p>
<p>P-R曲线,P%,R%</p>
<p>AP%</p>
<p><a href="mailto:&#109;&#65;&#80;&#x40;&#x30;&#x2e;&#53;">&#109;&#65;&#80;&#x40;&#x30;&#x2e;&#53;</a>(%)</p>
<p>parames-mAP curve</p>
<p>AveIoU%</p>
<p>混淆矩阵</p>
<p>FPS</p>
<p>参数量params</p>
<p>模型体积MB</p>
<p>GFLOPS</p>
<p>实验环境</p>
<p>实验数据集</p>
<p>锚框优化 K-means++聚类算法</p>
<p>消融实验</p>
<p>增加改进点</p>
<p>P%,R%,mAP%</p>
<p>图片对比效果</p>
<p>平均召回率和平均准确率是取训练完后最好的效果进行测试得出的结果，还是在训练过程中他们在不同epoch阶段出现的各自最好的结果？</p>
<p>平均召回率和平均准确率通常是在模型训练完成后,使用hold-out测试集(独立于训练集的数据集)进行评估得到的。具体来说:</p>
<ol>
<li><p>对于每个epoch,模型在训练集上的表现不能完全反映模型的真实能力,因为模型可能在训练集上过拟合了。</p>
</li>
<li><p>因此,我们保留一部分数据作为测试集,在每个epoch完成后,在这个测试集上评估模型,获得该epoch的召回率和准确率。</p>
</li>
<li><p>通常,我们选择在整个训练过程中,测试集上表现最佳的那个epoch,并报告该epoch的平均召回率和平均准确率作为模型的最终指标。</p>
</li>
<li><p>也就是说,报告的平均召回率和准确率,是在模型收敛并取得在测试集上最佳表现时的指标,而不是简单地取训练过程中每个epoch的最大值。</p>
</li>
</ol>
<p>这种做法能够更客观公正地评估模型的真实能力,防止过度拟合训练数据。同时通过监控每个epoch的表现,可以观察模型收敛的过程。</p>

        </div>

        
            <section class="post-copyright">
                
                    <p class="copyright-item">
                        <span>Author:</span>
                        <span>WuBoyue</span>
                    </p>
                
                
                    <p class="copyright-item">
                        <span>Permalink:</span>
                        <span><a href="http://example.com/2024/05/13/CNN/">http://example.com/2024/05/13/CNN/</a></span>
                    </p>
                
                
                    <p class="copyright-item">
                        <span>License:</span>
                        <span>Copyright (c) 2019 <a target="_blank" rel="noopener" href="http://creativecommons.org/licenses/by-nc/4.0/">CC-BY-NC-4.0</a> LICENSE</span>
                    </p>
                
                
                     <p class="copyright-item">
                         <span>Slogan:</span>
                         <span>Do you believe in <strong>DESTINY</strong>?</span>
                     </p>
                

            </section>
        
        <section class="post-tags">
            <div>
                <span>Tag(s):</span>
                <span class="tag">
                    
                    
                        <a href="/tags/AI%E7%AE%97%E6%B3%95/"># AI算法</a>
                    
                        
                </span>
            </div>
            <div>
                <a href="javascript:window.history.back();">back</a>
                <span>· </span>
                <a href="/">home</a>
            </div>
        </section>
        <section class="post-nav">
            
                <a class="prev" rel="prev" href="/2024/05/19/STA-%E9%9D%99%E6%80%81%E6%97%B6%E5%BA%8F%E5%88%86%E6%9E%90/">STA-静态时序分析</a>
            
            
            <a class="next" rel="next" href="/2024/05/11/cnnacc/">cnnacc</a>
            
        </section>


    </article>
</div>

            </div>
            <footer id="footer" class="footer">
    <div class="copyright">
        <span>© WuBoyue | Powered by <a href="https://hexo.io" target="_blank">Hexo</a> & <a href="https://github.com/Siricee/hexo-theme-Chic" target="_blank">Chic</a></span>
    </div>
</footer>

    </div>
</body>

</html>